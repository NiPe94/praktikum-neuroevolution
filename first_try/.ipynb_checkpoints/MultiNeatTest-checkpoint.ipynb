{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import time\n",
    "\n",
    "import MultiNEAT as NEAT\n",
    "import MultiNEAT.viz as viz\n",
    "import random as rnd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "rng = NEAT.RNG()\n",
    "rng.TimeSeed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = NEAT.Parameters()\n",
    "params.PopulationSize = 30\n",
    "params.DynamicCompatibility = True\n",
    "params.WeightDiffCoeff = 1.0\n",
    "params.CompatTreshold = 2.0\n",
    "params.YoungAgeTreshold = 15\n",
    "params.SpeciesMaxStagnation = 15\n",
    "params.OldAgeTreshold = 35\n",
    "params.MinSpecies = 2\n",
    "params.MaxSpecies = 4\n",
    "params.RouletteWheelSelection = False\n",
    "params.Elitism = True\n",
    "params.RecurrentProb = 0.15\n",
    "params.OverallMutationRate = 0.2\n",
    "\n",
    "params.MutateWeightsProb = 0.8\n",
    "params.MutateNeuronTimeConstantsProb = 0.1\n",
    "params.MutateNeuronBiasesProb = 0.1\n",
    "\n",
    "params.WeightMutationMaxPower = 0.5\n",
    "params.WeightReplacementMaxPower = 1.0\n",
    "params.MutateWeightsSevereProb = 0.5\n",
    "params.WeightMutationRate = 0.25\n",
    "\n",
    "params.TimeConstantMutationMaxPower = 0.1\n",
    "params.BiasMutationMaxPower = params.WeightMutationMaxPower\n",
    "\n",
    "params.MaxWeight = 8\n",
    "\n",
    "params.MutateAddNeuronProb = 0.1\n",
    "params.MutateAddLinkProb = 0.2\n",
    "params.MutateRemLinkProb = 0.0\n",
    "\n",
    "params.MinActivationA  = 1.0\n",
    "params.MaxActivationA  = 6.0\n",
    "\n",
    "params.MinNeuronTimeConstant = 0.04\n",
    "params.MaxNeuronTimeConstant = 0.24\n",
    "\n",
    "params.MinNeuronBias = -params.MaxWeight\n",
    "params.MaxNeuronBias = params.MaxWeight\n",
    "\n",
    "params.ActivationFunction_SignedSigmoid_Prob = 0.0\n",
    "params.ActivationFunction_UnsignedSigmoid_Prob = 0.0\n",
    "params.ActivationFunction_Tanh_Prob = 1.0\n",
    "params.ActivationFunction_SignedStep_Prob = 0.0\n",
    "params.ActivationFunction_Linear_Prob = 0.0\n",
    "\n",
    "params.CrossoverRate = 0.75  # mutate only 0.25\n",
    "params.MultipointCrossoverRate = 0.4\n",
    "params.SurvivalRate = 0.2\n",
    "\n",
    "params.MutateNeuronTraitsProb = 0\n",
    "params.MutateLinkTraitsProb = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 15\n",
    "render_during_training = 0\n",
    "\n",
    "g = NEAT.Genome(0, 9, 0, 4, False,NEAT.ActivationFunction.TANH, NEAT.ActivationFunction.TANH, 0, params, 0)\n",
    "pop = NEAT.Population(g, params, True, 1.0, rnd.randint(0, 1000))\n",
    "\n",
    "\n",
    "hof = []\n",
    "maxf_ever = 0\n",
    "\n",
    "env = gym.make('LunarLander-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward range: (-inf, inf)\n",
      "action space: Discrete(4)\n",
      "observation space: Box(8,)\n"
     ]
    }
   ],
   "source": [
    "print('reward range: '+str(env.env.reward_range))\n",
    "print('action space: '+str(env.action_space))\n",
    "print('observation space: '+str(env.observation_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation list => net output list\n",
    "def interact_with_nn():\n",
    "    global out\n",
    "    inp = observation.tolist()\n",
    "    net.Input(inp + [1.0])\n",
    "    net.ActivateLeaky(0.1)\n",
    "    out = list(net.Output())\n",
    "    return inp\n",
    "\n",
    "# reach within 300 time steps the goal or loose while doing it\n",
    "# => current total sum of all rewards from all done trials till the current trial\n",
    "def do_trial():\n",
    "    global observation, reward, t, img, action, done, info, avg_reward\n",
    "    observation = env.reset()\n",
    "    net.Flush()\n",
    "\n",
    "    f = 0\n",
    "    \n",
    "    # try within a maximum of 300 render steps to reach the goal\n",
    "    for t in range(300):\n",
    "\n",
    "        if render_during_training:\n",
    "            time.sleep(0.01)\n",
    "            env.render()\n",
    "\n",
    "        # interact with NN\n",
    "        inp = interact_with_nn()\n",
    "\n",
    "        if render_during_training:\n",
    "            img = viz.Draw(net)\n",
    "            cv2.imshow(\"current best\", img)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "        action = np.argmax(out)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done: break\n",
    "\n",
    "        f += reward\n",
    "\n",
    "    avg_reward += f\n",
    "    return avg_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [02:52, 41.71s/it]"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\n",
    "    for generation in range(20):\n",
    "\n",
    "        for i_episode, genome in tqdm(enumerate(NEAT.GetGenomeList(pop))):\n",
    "\n",
    "            net = NEAT.NeuralNetwork()\n",
    "            genome.BuildPhenotype(net)\n",
    "\n",
    "            avg_reward = 0\n",
    "\n",
    "            for trial in range(trials):\n",
    "\n",
    "                avg_reward += do_trial()\n",
    "\n",
    "            avg_reward /= trials\n",
    "\n",
    "            #print(avg_reward)\n",
    "\n",
    "            genome.SetFitness(1000000 + avg_reward)\n",
    "\n",
    "        maxf = max([x.GetFitness() for x in NEAT.GetGenomeList(pop)])\n",
    "        print('Generation: {}, max fitness: {}'.format(generation, maxf))\n",
    "\n",
    "        if maxf > maxf_ever:\n",
    "            hof.append(pickle.dumps(pop.GetBestGenome()))\n",
    "            maxf_ever = maxf\n",
    "\n",
    "        pop.Epoch()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Replaying forever..')\n",
    "\n",
    "if hof:\n",
    "    while True:\n",
    "        try:\n",
    "            observation = env.reset()\n",
    "            net = NEAT.NeuralNetwork()\n",
    "            g = pickle.loads(hof[-1])\n",
    "            g.BuildPhenotype(net)\n",
    "            reward = 0\n",
    "\n",
    "            for t in range(250):\n",
    "\n",
    "                time.sleep(0.01)\n",
    "                env.render()\n",
    "\n",
    "                # interact with NN\n",
    "                interact_with_nn()\n",
    "\n",
    "                # render NN\n",
    "                img = viz.Draw(net)\n",
    "                cv2.imshow(\"current best\", img)\n",
    "                cv2.waitKey(1)\n",
    "\n",
    "                action = np.argmax(out)\n",
    "                observation, reward, done, info = env.step(action)\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            time.sleep(0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
